# Federated Proximal policy Optimization Algorithm

## Abstract

> 这是一段的，大约两百字，我来写。

## Introduction

> 这个分很多段的，大约1500字，你们分着写。
>
> 第一段：介绍联邦学习
>
> 第二段：介绍强化学习
>
> 第三段：介绍联邦强化学习现有的工作，及其他们的不足。
>
> 第四段：针对以前联邦强化学习的不足，我们采取了什么的方法，进行了哪些工作。
>
> 第五段：对我们工作的总结，有什么贡献。
>
> 第六段：全文的结构是怎么样的。

## Related Work

> 分三段，大概写500字
>
> 第一段：联邦学习
>
> 第二段：分布式强化学习
>
> 第三段：多智能体强化学习

## Problem Definition

> 强化学习的优化目标
>
> 策略梯度的一些基本概念

## Our FPPO Approach

> PPO 的公式
>
> 联邦学习的公式
>
> FPPO的算法

## Experiments

> 三个实验：
>
> 1. gym做一个算法验证收敛性的实验
> 2. procgen，相同任务不同背景
> 3. procgen，不同任务

## Conclusion

> 一段大概200字

## References

> 参考文献

Leveraging Procedural Generation to BenchmarkReinforcement Learning
